{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import TargetEncoder, OneHotEncoder, MinMaxScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_test = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, TargetEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import xgboost \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import set_config\n",
    "\n",
    "#class_weight={0:1, 1:12}\n",
    "# Define the encoding strategy for features\n",
    "categorical_features = X_train.select_dtypes(include='object').columns\n",
    "numerical_features = X_train.select_dtypes(exclude=\"object\").columns\n",
    "n_unique_categories = X_train[categorical_features].nunique().sort_values(ascending=False)\n",
    "high_cardinality_features = n_unique_categories[n_unique_categories > 15].index\n",
    "low_cardinality_features = n_unique_categories[n_unique_categories <= 15].index\n",
    "\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "# Define the preprocessing steps for numeric features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "# Define the preprocessing steps for categorical features\n",
    "high_categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('targ', TargetEncoder()),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "# Define the preprocessing steps for categorical features\n",
    "low_categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))])\n",
    "\n",
    "# Use ColumnTransformer to apply the transformations to the correct columns in the dataframe\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('high_cat', high_categorical_transformer, high_cardinality_features),\n",
    "        ('low_cat', low_categorical_transformer, low_cardinality_features)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, TargetEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "steps7 = [('preprocessor', preprocessor), ('over', SMOTE()), \n",
    "          ('model',  GradientBoostingClassifier(learning_rate= 0.1, n_estimators= 50, random_state=1))]\n",
    "GradientBoosting_tuned = Pipeline(steps=steps7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X_test.iloc[0]\n",
    "test = test.to_dict()\n",
    "#df = pd.DataFrame([test])\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"NAME_CONTRACT_TYPE\": \"Cash loans\", \"CODE_GENDER\": \"F\", \"FLAG_OWN_CAR\": \"N\", \"FLAG_OWN_REALTY\": \"N\", \"CNT_CHILDREN\": 2, \"AMT_INCOME_TOTAL\": 99000.0, \"AMT_CREDIT\": 299772.0, \"AMT_ANNUITY\": 19647.0, \"AMT_GOODS_PRICE\": 247500.0, \"NAME_TYPE_SUITE\": \"Spouse, partner\", \"NAME_INCOME_TYPE\": \"Commercial associate\", \"NAME_EDUCATION_TYPE\": \"Secondary / secondary special\", \"NAME_FAMILY_STATUS\": \"Married\", \"NAME_HOUSING_TYPE\": \"House / apartment\", \"REGION_POPULATION_RELATIVE\": 0.0228, \"DAYS_BIRTH\": -12715, \"DAYS_EMPLOYED\": -2695.0, \"DAYS_REGISTRATION\": -6624.0, \"DAYS_ID_PUBLISH\": -2431, \"OWN_CAR_AGE\": NaN, \"FLAG_MOBIL\": 1, \"FLAG_EMP_PHONE\": 1, \"FLAG_WORK_PHONE\": 1, \"FLAG_CONT_MOBILE\": 1, \"FLAG_PHONE\": 1, \"FLAG_EMAIL\": 0, \"OCCUPATION_TYPE\": \"Laborers\", \"CNT_FAM_MEMBERS\": 4.0, \"REGION_RATING_CLIENT\": 2, \"REGION_RATING_CLIENT_W_CITY\": 2, \"WEEKDAY_APPR_PROCESS_START\": \"SUNDAY\", \"HOUR_APPR_PROCESS_START\": 13, \"REG_REGION_NOT_LIVE_REGION\": 0, \"REG_REGION_NOT_WORK_REGION\": 0, \"LIVE_REGION_NOT_WORK_REGION\": 0, \"REG_CITY_NOT_LIVE_CITY\": 0, \"REG_CITY_NOT_WORK_CITY\": 0, \"LIVE_CITY_NOT_WORK_CITY\": 0, \"ORGANIZATION_TYPE\": \"Industry: type 11\", \"EXT_SOURCE_1\": NaN, \"EXT_SOURCE_2\": 0.4471763180074513, \"EXT_SOURCE_3\": 0.2881295999178507, \"APARTMENTS_AVG\": 0.1227, \"BASEMENTAREA_AVG\": 0.1309, \"YEARS_BEGINEXPLUATATION_AVG\": 0.9796, \"YEARS_BUILD_AVG\": 0.7212, \"COMMONAREA_AVG\": 0.016, \"ELEVATORS_AVG\": 0.32, \"ENTRANCES_AVG\": 0.2759, \"FLOORSMAX_AVG\": 0.1667, \"FLOORSMIN_AVG\": 0.2083, \"LANDAREA_AVG\": 0.0241, \"LIVINGAPARTMENTS_AVG\": 0.1, \"LIVINGAREA_AVG\": 0.1148, \"NONLIVINGAPARTMENTS_AVG\": 0.0, \"NONLIVINGAREA_AVG\": 0.0, \"APARTMENTS_MODE\": 0.125, \"BASEMENTAREA_MODE\": 0.1358, \"YEARS_BEGINEXPLUATATION_MODE\": 0.9796, \"YEARS_BUILD_MODE\": 0.7321, \"COMMONAREA_MODE\": 0.0161, \"ELEVATORS_MODE\": 0.3222, \"ENTRANCES_MODE\": 0.2759, \"FLOORSMAX_MODE\": 0.1667, \"FLOORSMIN_MODE\": 0.2083, \"LANDAREA_MODE\": 0.0247, \"LIVINGAPARTMENTS_MODE\": 0.1093, \"LIVINGAREA_MODE\": 0.1196, \"NONLIVINGAPARTMENTS_MODE\": 0.0, \"NONLIVINGAREA_MODE\": 0.0, \"APARTMENTS_MEDI\": 0.1239, \"BASEMENTAREA_MEDI\": 0.1309, \"YEARS_BEGINEXPLUATATION_MEDI\": 0.9796, \"YEARS_BUILD_MEDI\": 0.7249, \"COMMONAREA_MEDI\": 0.0161, \"ELEVATORS_MEDI\": 0.32, \"ENTRANCES_MEDI\": 0.2759, \"FLOORSMAX_MEDI\": 0.1667, \"FLOORSMIN_MEDI\": 0.2083, \"LANDAREA_MEDI\": 0.0245, \"LIVINGAPARTMENTS_MEDI\": 0.1018, \"LIVINGAREA_MEDI\": 0.1168, \"NONLIVINGAPARTMENTS_MEDI\": 0.0, \"NONLIVINGAREA_MEDI\": 0.0, \"FONDKAPREMONT_MODE\": \"reg oper account\", \"HOUSETYPE_MODE\": \"block of flats\", \"TOTALAREA_MODE\": 0.099, \"WALLSMATERIAL_MODE\": \"Panel\", \"EMERGENCYSTATE_MODE\": \"No\", \"OBS_30_CNT_SOCIAL_CIRCLE\": 3.0, \"DEF_30_CNT_SOCIAL_CIRCLE\": 0.0, \"OBS_60_CNT_SOCIAL_CIRCLE\": 3.0, \"DEF_60_CNT_SOCIAL_CIRCLE\": 0.0, \"DAYS_LAST_PHONE_CHANGE\": -444.0, \"FLAG_DOCUMENT_2\": 0, \"FLAG_DOCUMENT_3\": 1, \"FLAG_DOCUMENT_4\": 0, \"FLAG_DOCUMENT_5\": 0, \"FLAG_DOCUMENT_6\": 0, \"FLAG_DOCUMENT_7\": 0, \"FLAG_DOCUMENT_8\": 0, \"FLAG_DOCUMENT_9\": 0, \"FLAG_DOCUMENT_10\": 0, \"FLAG_DOCUMENT_11\": 0, \"FLAG_DOCUMENT_12\": 0, \"FLAG_DOCUMENT_13\": 0, \"FLAG_DOCUMENT_14\": 0, \"FLAG_DOCUMENT_15\": 0, \"FLAG_DOCUMENT_16\": 0, \"FLAG_DOCUMENT_17\": 0, \"FLAG_DOCUMENT_18\": 0, \"FLAG_DOCUMENT_19\": 0, \"FLAG_DOCUMENT_20\": 0, \"FLAG_DOCUMENT_21\": 0, \"AMT_REQ_CREDIT_BUREAU_HOUR\": 0.0, \"AMT_REQ_CREDIT_BUREAU_DAY\": 0.0, \"AMT_REQ_CREDIT_BUREAU_WEEK\": 0.0, \"AMT_REQ_CREDIT_BUREAU_MON\": 0.0, \"AMT_REQ_CREDIT_BUREAU_QRT\": 0.0, \"AMT_REQ_CREDIT_BUREAU_YEAR\": 1.0, \"DAYS_EMPLOYED_ANOM\": 0, \"CREDIT_INCOME_PERCENT\": 3.028, \"ANNUITY_INCOME_PERCENT\": 0.1984545454545454, \"CREDIT_TERM\": 0.0655398102557944, \"DAYS_EMPLOYED_PERCENT\": 0.2119543845851356}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "t = json.dumps(test)\n",
    "print(t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, TargetEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def predict_bank(X, model):\n",
    "    \n",
    "    if type(X) == dict:\n",
    "        df = pd.DataFrame([X])\n",
    "    else:\n",
    "        df = pd.DataFrame(X).T\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_proba = model.predict_proba(df)[:, 1]\n",
    "    y_pred = (y_proba > 0.25).astype(\"int\")\n",
    "    \n",
    "    if y_pred == 0:\n",
    "        print('Client solvable :', \"la probabilité de faillite est de\",y_proba*100, \"%\")\n",
    "    elif y_pred == 1:\n",
    "        print('Client à risque :', \"la probabilité de faillite est de\",y_proba*100, \"%\")\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\camil\\Documents\\Projet7\\env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\camil\\Documents\\Projet7\\env\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client à risque : la probabilité de faillite est de [58.53210816] %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_bank(test, GradientBoosting_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create Model File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save to file in the current working directory\n",
    "pkl_filename = \"model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(GradientBoosting_tuned, file)\n",
    "\n",
    "# Load from file\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    pickle_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\camil\\Documents\\Projet7\\env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\camil\\Documents\\Projet7\\env\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client à risque : la probabilité de faillite est de [56.73408152] %\n"
     ]
    }
   ],
   "source": [
    "##loading the model from the saved file\n",
    "pkl_filename = \"model.pkl\"\n",
    "with open(pkl_filename, 'rb') as f_in:\n",
    "    model = pickle.load(f_in)\n",
    "\n",
    "predictValue = predict_bank(test, model)\n",
    "predictValue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
